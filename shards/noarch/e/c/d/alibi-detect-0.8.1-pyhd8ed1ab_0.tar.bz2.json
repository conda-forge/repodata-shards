{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": "[Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source Python library focused on **outlier**, **adversarial** and **drift** detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. Both **TensorFlow** and **PyTorch** backends are supported for drift detection.  - [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)  For more background on the importance of monitoring outliers and distributions in a production setting, check out [this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest) from the *Challenges in Deploying and Monitoring Machine Learning Systems* ICML 2020 workshop, based on the paper [Monitoring and explainability of models in production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.  For a thorough introduction to drift detection, check out [Protecting Your Machine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o). he talk covers what drift is and why it pays to detect it, the different types of drift, how it can be detected in a principled manner and also describes the anatomy of a drift detector.   PyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)",
    "dev_url": "https://github.com/SeldonIO/alibi-detect",
    "doc_source_url": null,
    "doc_url": "https://docs.seldon.io/projects/alibi-detect/en/latest/",
    "home": "https://github.com/SeldonIO/alibi-detect",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "Apache-2.0",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.8.1.tar.gz",
    "subdirs": [
      "noarch"
    ],
    "summary": "Algorithms for outlier detection, concept drift and metrics.",
    "tags": null,
    "text_prefix": false,
    "timestamp": 1643476181,
    "version": "0.8.1"
  },
  "channeldata_version": 1,
  "feedstock": "alibi-detect-feedstock",
  "labels": [
    "main"
  ],
  "package": "alibi-detect-0.8.1-pyhd8ed1ab_0.tar.bz2",
  "repodata": {
    "build": "pyhd8ed1ab_0",
    "build_number": 0,
    "depends": [
      "absl-py >=0.10.0,<0.11.0",
      "dill >=0.3.0,<0.4.0",
      "libgdal",
      "matplotlib-base >=3.0.0,<4.0.0",
      "numba >=0.50.0,!=0.54.0,<0.56.0",
      "numpy >=1.16.2,<2.0.0",
      "opencv >=3.2.0,<5.0.0",
      "pandas >=0.23.3,<2.0.0",
      "pillow >=5.4.1,<9.0.0",
      "python >=3.7",
      "requests >=2.21.0,<3.0.0",
      "scikit-image >=0.14.2,!=0.17.1,<0.19",
      "scikit-learn >=0.20.2,<1.1.0",
      "scipy >=1.3.0,<2.0.0",
      "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0",
      "tensorflow-probability >=0.8.0,<0.13.0",
      "tqdm >=4.28.1,<5.0.0",
      "transformers >=4.0.0,<5.0.0",
      "wrapt >=1.12.1,<1.13.0"
    ],
    "license": "Apache-2.0",
    "md5": "b841f58473a4c85f894b570838fbd110",
    "name": "alibi-detect",
    "noarch": "python",
    "sha256": "fa074cb9a60e7ae9db9c03550e1fcedb28676bbb50603d9ee138c3a2e1170bc8",
    "size": 169773,
    "subdir": "noarch",
    "timestamp": 1643476181816,
    "version": "0.8.1"
  },
  "repodata_version": 1,
  "subdir": "noarch",
  "url": "https://github.com/conda-forge/releases/releases/download/noarch/alibi-detect-0.8.1-pyhd8ed1ab_0.tar.bz2/alibi-detect-0.8.1-pyhd8ed1ab_0.tar.bz2"
}