{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": null,
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "http://tidypredict.netlify.com/",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "GPL-3",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": [
      "https://cran.r-project.org/src/contrib/Archive/tidypredict/tidypredict_0.2.0.tar.gz",
      "https://cran.r-project.org/src/contrib/tidypredict_0.2.0.tar.gz"
    ],
    "subdirs": [
      "noarch"
    ],
    "summary": "It parses a fitted 'R' model object, and returns a formula in 'Tidy Eval' code that calculates the predictions. It works with several databases back-ends because it leverages 'dplyr' and 'dbplyr' for the final 'SQL' translation of the algorithm. It currently supports lm(), glm(), randomForest() and ranger() models.",
    "tags": null,
    "text_prefix": false,
    "timestamp": 1542789567,
    "version": "0.2.0"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "main",
    "cf202003"
  ],
  "package": "r-tidypredict-0.2.0-r351h6115d3f_1000.tar.bz2",
  "repodata": {
    "build": "r351h6115d3f_1000",
    "build_number": 1000,
    "depends": [
      "r-base >=3.5.1,<3.5.2.0a0",
      "r-dplyr >=0.7",
      "r-purrr",
      "r-rlang",
      "r-tibble",
      "r-tidyr"
    ],
    "license": "GPL-3",
    "license_family": "GPL3",
    "md5": "ce4bb12a8f873982ffbdf0f110417070",
    "name": "r-tidypredict",
    "noarch": "generic",
    "sha256": "bf0652d2490bcab22fd7eb9719fbe68d536d0c137d356553be97967c90ffa989",
    "size": 113601,
    "subdir": "noarch",
    "timestamp": 1542789567238,
    "version": "0.2.0"
  },
  "repodata_version": 1,
  "subdir": "noarch",
  "url": "https://conda.anaconda.org/conda-forge/noarch/r-tidypredict-0.2.0-r351h6115d3f_1000.tar.bz2"
}