{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": null,
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "https://github.com/grf-labs/policytree",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "GPL-3.0-only",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": [
      "https://cran.r-project.org/src/contrib/Archive/policytree/policytree_1.0.4.tar.gz",
      "https://cran.r-project.org/src/contrib/policytree_1.0.4.tar.gz"
    ],
    "subdirs": [
      "win-64"
    ],
    "summary": "Learn optimal policies via doubly robust empirical welfare maximization over trees. This package implements the multi-action doubly robust approach of Zhou, Athey and Wager (2018) <arXiv:1810.04778> in the case where we want to learn policies that belong to the class of depth k decision trees.",
    "tags": null,
    "text_prefix": false,
    "timestamp": 1623861367,
    "version": "1.0.4"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "main"
  ],
  "package": "r-policytree-1.0.4-r36ha856d6a_0.tar.bz2",
  "repodata": {
    "build": "r36ha856d6a_0",
    "build_number": 0,
    "depends": [
      "m2w64-gcc-libs",
      "r-base >=3.6,<3.7.0a0",
      "r-bh",
      "r-grf >=1.1.0",
      "r-rcpp"
    ],
    "license": "GPL-3.0-only",
    "license_family": "GPL3",
    "md5": "eca81c5e582d626e2b5bb94bc299d809",
    "name": "r-policytree",
    "sha256": "456f813beb1d503b33bf5a95b56b3e1e8843a1060a27ece53ed683a9128f735e",
    "size": 156407,
    "subdir": "win-64",
    "timestamp": 1623861367187,
    "version": "1.0.4"
  },
  "repodata_version": 1,
  "subdir": "win-64",
  "url": "https://github.com/conda-forge/releases/releases/download/win-64/r-policytree-1.0.4-r36ha856d6a_0.tar.bz2/r-policytree-1.0.4-r36ha856d6a_0.tar.bz2"
}