{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": null,
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "https://github.com/microsoft/onnxruntime/",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "MIT",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": null,
    "subdirs": [
      "linux-aarch64"
    ],
    "summary": "cross-platform, high performance ML inferencing and training accelerator",
    "tags": null,
    "text_prefix": true,
    "timestamp": 1649159363,
    "version": "1.10.0"
  },
  "channeldata_version": 1,
  "feedstock": "onnxruntime-feedstock",
  "labels": [
    "main"
  ],
  "package": "onnxruntime-1.10.0-py38h355c43a_4.tar.bz2",
  "repodata": {
    "build": "py38h355c43a_4",
    "build_number": 4,
    "depends": [
      "libgcc-ng >=10.3.0",
      "libprotobuf >=3.19.4,<3.20.0a0",
      "libstdcxx-ng >=10.3.0",
      "numpy >=1.19.5,<2.0a0",
      "protobuf",
      "python >=3.8,<3.9.0a0",
      "python >=3.8,<3.9.0a0 *_cpython",
      "python-flatbuffers",
      "python_abi 3.8.* *_cp38",
      "re2 >=2022.4.1,<2022.4.2.0a0"
    ],
    "license": "MIT",
    "md5": "3401d72b461e5d4f0f21dc4ad8408afc",
    "name": "onnxruntime",
    "sha256": "5e255ec7388dacb31b37f1ea0f49d71cda2e5b023ceecb6977bdd36b3f1361ca",
    "size": 4640958,
    "subdir": "linux-aarch64",
    "timestamp": 1649159363801,
    "version": "1.10.0"
  },
  "repodata_version": 1,
  "subdir": "linux-aarch64",
  "url": "https://github.com/conda-forge/releases/releases/download/linux-aarch64/onnxruntime-1.10.0-py38h355c43a_4.tar.bz2/onnxruntime-1.10.0-py38h355c43a_4.tar.bz2"
}