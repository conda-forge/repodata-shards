{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": "cw-eval is an evaluation suite for scoring entries in geospatial image analysis competitions. It includes tools for calculating IoU scores, precision, recall, F1 score, and scripts to score entire entries in either geojson or csv formats.",
    "dev_url": "https://github.com/cosmiq/cw-eval",
    "doc_source_url": null,
    "doc_url": "http://cw-eval.readthedocs.io/",
    "home": "http://github.com/cosmiq/cw-eval",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "Apache-2.0",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": "https://pypi.io/packages/source/c/cw-eval/cw_eval-0.3.tar.gz",
    "subdirs": [
      "osx-64"
    ],
    "summary": "Evaluation metrics for Geospatial Machine Learning Challenges",
    "tags": null,
    "text_prefix": true,
    "timestamp": 1545070099,
    "version": "0.3"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "main",
    "cf202003"
  ],
  "package": "cw-eval-0.3-py36h470a237_0.tar.bz2",
  "repodata": {
    "build": "py36h470a237_0",
    "build_number": 0,
    "depends": [
      "geopandas",
      "pandas",
      "python >=3.6,<3.7.0a0",
      "rtree",
      "shapely",
      "tqdm"
    ],
    "license": "Apache-2.0",
    "license_family": "Apache",
    "md5": "563eb6e5e5550de5ca77fc5376834976",
    "name": "cw-eval",
    "sha256": "25426a70e4088c218877cada04b09533584f42ab0504a295393e5e24b8a8282e",
    "size": 22151,
    "subdir": "osx-64",
    "timestamp": 1545070099581,
    "version": "0.3"
  },
  "repodata_version": 1,
  "subdir": "osx-64",
  "url": "https://conda.anaconda.org/conda-forge/osx-64/cw-eval-0.3-py36h470a237_0.tar.bz2"
}