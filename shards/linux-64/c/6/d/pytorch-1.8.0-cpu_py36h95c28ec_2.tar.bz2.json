{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": null,
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "https://pytorch.org/",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "BSD-3-Clause",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": "https://github.com/pytorch/pytorch.git",
    "source_url": null,
    "subdirs": [
      "linux-64"
    ],
    "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.",
    "tags": null,
    "text_prefix": true,
    "timestamp": 1626805278,
    "version": "1.8.0"
  },
  "channeldata_version": 1,
  "feedstock": "pytorch-cpu-feedstock",
  "labels": [
    "main"
  ],
  "package": "pytorch-1.8.0-cpu_py36h95c28ec_2.tar.bz2",
  "repodata": {
    "build": "cpu_py36h95c28ec_2",
    "build_number": 2,
    "depends": [
      "__glibc >=2.17,<3.0.a0",
      "_openmp_mutex >=4.5",
      "cffi",
      "dataclasses",
      "future",
      "libblas * *_mkl",
      "libblas >=3.9.0,<4.0a0",
      "libgcc-ng >=7.5.0",
      "libprotobuf >=3.16.0,<3.17.0a0",
      "libstdcxx-ng >=7.5.0",
      "mkl >=2020.4,<2021.0a0",
      "ninja",
      "numpy >=1.17.5,<2.0a0",
      "python >=3.6,<3.7.0a0",
      "python_abi 3.6.* *_cp36m",
      "sleef >=3.5.1,<4.0a0",
      "typing_extensions"
    ],
    "license": "BSD-3-Clause",
    "license_family": "BSD",
    "md5": "4a5b62f8dc021407067dc8d42b1903f9",
    "name": "pytorch",
    "sha256": "f0e096b9899926476ea7b2b314593b5f4ff4a0b2f151d5ef1cc249ffd4db965b",
    "size": 45519163,
    "subdir": "linux-64",
    "timestamp": 1626805278722,
    "version": "1.8.0"
  },
  "repodata_version": 1,
  "subdir": "linux-64",
  "url": "https://github.com/conda-forge/releases/releases/download/linux-64/pytorch-1.8.0-cpu_py36h95c28ec_2.tar.bz2/pytorch-1.8.0-cpu_py36h95c28ec_2.tar.bz2"
}