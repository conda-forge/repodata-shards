{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": "This repository contains op-for-op PyTorch reimplementations, pre-trained models and fine-tuning examples for:   - Google's BERT model,   - OpenAI's GPT model,   - Google/CMU's Transformer-XL model, and   - OpenAI's GPT-2 model. These implementations have been tested on several datasets (see the examples) and should match the performances of the associated TensorFlow implementations (e.g. ~91 F1 on SQuAD for BERT, ~88 F1 on RocStories for OpenAI GPT and ~18.3 perplexity on WikiText 103 for the Transformer-XL).",
    "dev_url": "https://github.com/huggingface/pytorch-pretrained-BERT",
    "doc_source_url": null,
    "doc_url": "https://github.com/huggingface/pytorch-pretrained-BERT",
    "home": "https://github.com/huggingface/pytorch-pretrained-BERT",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "Apache-2.0",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": "https://pypi.io/packages/source/p/pytorch-pretrained-bert/pytorch_pretrained_bert-0.6.2.tar.gz",
    "subdirs": [
      "linux-64"
    ],
    "summary": "PyTorch version of Google AI BERT model with script to load Google pre-trained models",
    "tags": null,
    "text_prefix": true,
    "timestamp": 1557485220,
    "version": "0.4.0"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "main"
  ],
  "package": "pytorch-pretrained-bert-0.4.0-py36_1000.tar.bz2",
  "repodata": {
    "build": "py36_1000",
    "build_number": 1000,
    "constrains": [
      "python_abi * *_cp36m"
    ],
    "depends": [
      "boto3",
      "numpy",
      "python >=3.6,<3.7.0a0",
      "pytorch >=0.4.1",
      "requests",
      "tqdm"
    ],
    "license": "Apache 2.0",
    "license_family": "Apache",
    "md5": "8bbf29abc914aeaacd7843242c8c3506",
    "name": "pytorch-pretrained-bert",
    "sha256": "6bca8fda60e26ab7b9de9452d1109985d493e72b07ee755820a0bc4b53e7f2b1",
    "size": 54363,
    "subdir": "linux-64",
    "timestamp": 1545432515187,
    "version": "0.4.0"
  },
  "repodata_version": 1,
  "subdir": "linux-64",
  "url": "https://conda.anaconda.org/conda-forge/linux-64/pytorch-pretrained-bert-0.4.0-py36_1000.tar.bz2"
}