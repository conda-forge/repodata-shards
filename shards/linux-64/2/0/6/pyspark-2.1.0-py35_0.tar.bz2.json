{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": "Apache Spark is a fast and general engine for large-scale data processing.",
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "http://spark.apache.org/",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "Apache 2.0",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": "http://www.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz",
    "subdirs": [
      "linux-64"
    ],
    "summary": "Apache Spark",
    "tags": null,
    "text_prefix": true,
    "timestamp": 0,
    "version": "2.1.0"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "cf202003",
    "main",
    "cf201901"
  ],
  "package": "pyspark-2.1.0-py35_0.tar.bz2",
  "repodata": {
    "build": "py35_0",
    "build_number": 0,
    "depends": [
      "numpy >=1.7",
      "pandas",
      "py4j 0.10.4",
      "python 3.5*"
    ],
    "license": "Apache 2.0",
    "md5": "e11568dbf470307fd4c348211784a2d6",
    "name": "pyspark",
    "sha256": "4770f93276393e74d2c55aed4f1c0fd5a4c6db7f50f45ab7dc17afb0304ca5f6",
    "size": 181203973,
    "subdir": "linux-64",
    "version": "2.1.0"
  },
  "repodata_version": 1,
  "subdir": "linux-64",
  "url": "https://conda.anaconda.org/conda-forge/linux-64/pyspark-2.1.0-py35_0.tar.bz2"
}