{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": null,
    "dev_url": null,
    "doc_source_url": null,
    "doc_url": null,
    "home": "https://github.com/boost-R/mboost",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "GPL-2",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": null,
    "source_url": [
      "https://cran.r-project.org/src/contrib/Archive/mboost/mboost_2.9-1.tar.gz",
      "https://cran.r-project.org/src/contrib/mboost_2.9-1.tar.gz"
    ],
    "subdirs": [
      "linux-64"
    ],
    "summary": "Functional gradient descent algorithm (boosting) for optimizing general risk functions utilizing component-wise (penalised) least squares estimates or regression trees as base-learners for fitting generalized linear, additive and interaction models to potentially high-dimensional data.",
    "tags": null,
    "text_prefix": false,
    "timestamp": 1563465100,
    "version": "2.9_1"
  },
  "channeldata_version": 1,
  "feedstock": null,
  "labels": [
    "main",
    "cf202003"
  ],
  "package": "r-mboost-2.9_1-r35hcdcec82_1001.tar.bz2",
  "repodata": {
    "build": "r35hcdcec82_1001",
    "build_number": 1001,
    "depends": [
      "libgcc-ng >=7.3.0",
      "r-base >=3.5,<3.6.0a0",
      "r-lattice",
      "r-matrix",
      "r-nnls",
      "r-partykit >=1.2_1",
      "r-quadprog",
      "r-stabs >=0.5_0",
      "r-survival"
    ],
    "license": "GPL-2",
    "license_family": "GPL2",
    "md5": "450dc20fb91d3d1e2141c13a61214ef7",
    "name": "r-mboost",
    "sha256": "54527f5f0b7a0389725887e92491ee7c09a80cf94b4f948091e8b7a7b914e776",
    "size": 2494869,
    "subdir": "linux-64",
    "timestamp": 1563465100033,
    "version": "2.9_1"
  },
  "repodata_version": 1,
  "subdir": "linux-64",
  "url": "https://conda.anaconda.org/conda-forge/linux-64/r-mboost-2.9_1-r35hcdcec82_1001.tar.bz2"
}