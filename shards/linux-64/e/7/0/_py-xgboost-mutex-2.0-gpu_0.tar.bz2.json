{
  "channeldata": {
    "activate.d": false,
    "binary_prefix": false,
    "deactivate.d": false,
    "description": "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.",
    "dev_url": "https://github.com/dmlc/xgboost/",
    "doc_source_url": null,
    "doc_url": "https://xgboost.readthedocs.io/",
    "home": "https://github.com/dmlc/xgboost",
    "icon_hash": null,
    "icon_url": null,
    "identifiers": null,
    "keywords": null,
    "license": "Apache-2.0",
    "post_link": false,
    "pre_link": false,
    "pre_unlink": false,
    "recipe_origin": null,
    "run_exports": {},
    "source_git_url": "https://github.com/dmlc/xgboost",
    "source_url": null,
    "subdirs": [
      "linux-64"
    ],
    "summary": "Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlow",
    "tags": null,
    "text_prefix": false,
    "timestamp": 1644957785,
    "version": "2.0"
  },
  "channeldata_version": 1,
  "feedstock": "xgboost-feedstock",
  "labels": [
    "main"
  ],
  "package": "_py-xgboost-mutex-2.0-gpu_0.tar.bz2",
  "repodata": {
    "build": "gpu_0",
    "build_number": 1,
    "depends": [],
    "license": "Apache-2.0",
    "md5": "7702188077361f43a4d61e64c694f850",
    "name": "_py-xgboost-mutex",
    "sha256": "ef6bccb4e2114a7be586416f5e1a8656ffa11c6fddef926b5c6d5ff5179157fa",
    "size": 12330,
    "subdir": "linux-64",
    "timestamp": 1644957785078,
    "version": "2.0"
  },
  "repodata_version": 1,
  "subdir": "linux-64",
  "url": "https://github.com/conda-forge/releases/releases/download/linux-64/_py-xgboost-mutex-2.0-gpu_0.tar.bz2/_py-xgboost-mutex-2.0-gpu_0.tar.bz2"
}